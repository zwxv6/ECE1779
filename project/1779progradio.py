# -*- coding: utf-8 -*-
"""1779proGradio.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yggSIprZSpIxmOxeXnN-xZAc7IQIaMTl
"""

import gradio as gr

import torch
import torchtext
from sklearn.model_selection import train_test_split
import torch.nn.functional as F

glove = torchtext.vocab.GloVe(name="6B",dim=100) # embedding size = 100

class CNNModel(torch.nn.Module):
  def __init__(self, vocab,k1,k2,n1,n2):
    super().__init__()
    self.k1 = (k1, 100)
    self.k2 = (k2, 100)
    self.n1 = n1
    self.n2 = n2
    self.probabilityFunction = torch.nn.Sigmoid()

    self.embedding = torch.nn.Embedding.from_pretrained(vocab.vectors)

    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=self.n1, kernel_size=self.k1, bias=False)
    self.bn1 = torch.nn.BatchNorm2d(self.n1)
    self.maxpool1 = torch.nn.AdaptiveMaxPool2d(output_size=(1, 1))

    self.conv2 = torch.nn.Conv2d(in_channels=1, out_channels=self.n2, kernel_size=self.k2, bias=False)
    self.bn2 = torch.nn.BatchNorm2d(self.n2)
    self.maxpool2 = torch.nn.AdaptiveMaxPool2d(output_size=(1, 1))

    self.out = torch.nn.Linear(self.n1+self.n2, 1)

  def forward(self, x):
    e = self.embedding(x)
    input = torch.transpose(e, 0, 1).unsqueeze(1)
    x1 = self.conv1(input)
    x1 = F.relu(x1)
    x1 = self.bn1(x1)
    x1 = self.maxpool1(x1)

    x2 = self.conv2(input)
    x2 = F.relu(x2)
    x2 = self.bn2(x2)
    x2 = self.maxpool2(x2)

    concatenate = torch.cat((x1, x2), dim=1)
    output = self.out(concatenate.squeeze())
    logits = self.probabilityFunction(output)

    return logits.reshape([-1])

def runModel(sentence,type = 'CNN Model'):
  probabilityFunction = torch.nn.Sigmoid()

  if type == 'CNN Model':
    checkpoint = torch.load('CNNModel.pt')
    model = CNNModel(glove,k1=2,k2=4,n1=20,n2=20)
    model.load_state_dict(checkpoint)
    model.eval()

    tokens = sentence.split()
    token_ints = [glove.stoi.get(tok, len(glove.stoi)-1) for tok in tokens]
    token_tensor = torch.LongTensor(token_ints).view(-1,1)

    mark = 0
    if len(token_tensor) < 4:
      temp = []
      for i in range(len(token_tensor)):
        temp.append([int(token_tensor[i].detach().numpy())])
      while(mark == 0):
        if len(temp) < 4:
          temp.append([1])
        else:
          mark = 1
      token_tensor = torch.tensor(temp)
    logit = model(x=token_tensor)
    probability = probabilityFunction(logit)
    probability = torch.maximum(probability, torch.tensor([1e-5]))
    probability = torch.minimum(probability, torch.tensor([0.99999]))
    Y_pred = torch.round(probability)

  if Y_pred == 1:
    result = 'Real News'
  elif Y_pred == 0:
    result = 'Fake News'

  return result

gr.Interface(fn=runModel,
      inputs=["text",
      gr.Radio(['CNN Model'])
      ],
      outputs="text").launch(share=True)